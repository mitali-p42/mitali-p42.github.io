{"status":"ok","feed":{"url":"https://medium.com/feed/@mpotnis","title":"Stories by Mitali Potnis on Medium","link":"https://medium.com/@mpotnis?source=rss-bd16ccb70401------2","author":"","description":"Stories by Mitali Potnis on Medium","image":"https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png"},"items":[{"title":"Enhancing Movie Recommendation Systems with Auto-Surprise","pubDate":"2023-04-04 03:13:18","link":"https://medium.com/@mpotnis/enhancing-movie-recommendation-systems-with-auto-surprise-34b4a6f5b0dd?source=rss-bd16ccb70401------2","guid":"https://medium.com/p/34b4a6f5b0dd","author":"Mitali Potnis","thumbnail":"https://cdn-images-1.medium.com/max/1024/1*wjA4BHRf1zyHJn_EVor1Yg.jpeg","description":"\n<blockquote>Developed using popular libraries like Surprise for recommender algorithms and Hyperopt for hyperparameter tuning, Auto-Surprise streamlines the process of building machine learning models for recommendation systems by allowing automated algorithm selection and hyperparameter optimization.</blockquote>\n<figure><img alt=\"Movies\" src=\"https://cdn-images-1.medium.com/max/1024/1*wjA4BHRf1zyHJn_EVor1Yg.jpeg\"></figure><h4><strong>Motivation and Background</strong></h4>\n<p>In the world of movie recommendations, the importance of data and machine learning has grown exponentially. However, building machine learning recommender models can be complex due to the many variables involved. As a result, several AutoML solutions have emerged, allowing for the automation of tasks like data pre-processing, algorithm selection, hyperparameter tuning, and ensemble modeling.</p>\n<p>One such AutoML tool is Auto-suprise that automates algorithm selection and hyperparameter optimization in a highly parallelized manner, making it a powerful tool for movie recommendation systems. In this blog post, we will explore the features of Auto-suprise and provide an example of how to use it for movie recommendations.</p>\n<h4><strong>Introduction</strong></h4>\n<p>Auto-Surprise is an open source Auto Recommender System library Python library that uses parallel Sequential Model-Based Optimization approach with Tree of Parzens Estimators (TPE) for hyperparameter tuning. Auto- Surprise is built on the Python Surprise library. Surprise is a popular python library which specializes in analyzing and building recommendation models. It provides a variety of algorithms like Normal Predictor (Random), K-Nearest Neighbors (KNN) Basic, KNN with Means, KNN with Z-Score, KNN with Baseline, Singular Value Decomposition (SVD), SVD++, Negative Matrix-Factorization (NMF), Co-Clustering, Slope\u00a0One.</p>\n<p>The Surprise library provides a built-in module that allows Grid Search or Random Search for hyperparamater optimization. However, when it comes to optimizing machine learning models, manually conducting a random search or using GridSearch can be time-consuming and inefficient due to large number of iterations. This can be computationally expensive as well as time consuming. This is where automated methods like Auto-Surprise come in handy. Developed to simplify the algorithm and hyperparameter tuning process, Auto-Surprise is a powerful tool that\u2019s easy to use, even for those who are new to the\u00a0field.</p>\n<h4><strong>Auto-Surprise Optimization Strategy</strong></h4>\n<p>Auto-Surprise leverages a parallel Sequential Model Based Optimization (SMBO) approach to optimize the performance of the recommendation models. SMBO is an iterative optimization method where multiple experiments are conducted sequentially on a surrogate function. The results of each experiment are recorded, and the optimal hyperparameters are determined based on the historical performance of the surrogate function.</p>\n<p>To begin the optimization process, Auto-Surprise sets a minimum loss for the dataset using a random prediction algorithm that each recommendation algorithm must achieve. The algorithms are then optimized in parallel until either a user-defined time limit or a maximum number of evaluations is reached. If any algorithm performs worse than the baseline after a certain number of evaluations, it is excluded from further optimization.</p>\n<p>Auto-Surprise returns the best performing algorithm with the optimized hyperparameters, along with a dictionary containing the performance metrics of all the algorithms. This makes it easy to compare and analyze the performance of different recommendation models. The figure below illustrates the optimization strategy of Auto-Surprise.</p>\n<figure><img alt=\"Optimization strategy for Auto-Surprise\" src=\"https://cdn-images-1.medium.com/max/1024/1*IWYVHrQ3OpBuLwBo3sc2xw.png\"><figcaption>Optimization strategy of Auto-Surprise</figcaption></figure><h4><strong>Movie Recommendation using Auto-Surprise</strong></h4>\n<p>We will now be looking at a scenario where we employ Auto-Surprise for the goal of predicting or recommending movies to users based on the IDs of the user and movies. Using auto-surprise, we can effectively build a movie recommendation model with ease. In my example, I have utilized a dataset that has been gathered using the Kafka streaming platform. However, one can use other readily available datasets like that of <a href=\"https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset\">MovieLens dataset</a> that contains user ratings for various\u00a0movies.</p>\n<p><em>Setting up Auto-Surprise</em></p>\n<p>To begin we first need to install the required dependencies:</p>\n<pre># Installing the required libraries<br>!pip install hyperopt==0.2.5<br>!pip install scikit-surprise<br>!pip install auto-surprise</pre>\n<p>Once we have downloaded the packages and libraries, we can import them using the following python\u00a0code:</p>\n<pre>#Importing the required libraries<br>import hyperopt<br>from surprise import Reader, Dataset<br>from auto_surprise.engine import Engine<br>import pandas as pd<br>import numpy as np</pre>\n<p><em>Reading the data and building the data\u00a0frame</em></p>\n<p>We will be reading the dataset which is stored in a csv format using the read_csv() function of the pandas library. Once we have stored the pandas dataframe we then define the reader using Reader class for parsing the file containing ratings. We then convert the pandas dataframe into a dataset format which can be read for training our\u00a0model.</p>\n<pre># Reading the data from the csv file<br>df = pd.read_csv(&lt;your dataset.csv name in string format&gt;)<br># Building the dataframe for the models using the pandas dataframe<br>reader = Reader(rating_scale=(1,5))<br>data = Dataset.load_from_df(df[['user', 'movie', 'rate']], reader)</pre>\n<p><em>Initializing Auto-Surprise Engine</em></p>\n<p>Once we have read the data and converted it into a suitable form, we then initialize the engine using the Engine class for Auto-Surprise.</p>\n<pre># Intitializing the auto surprise engine with the possible algorithms.<br>engine = Engine(verbose=True, algorithms=[\"svd\", \"svdpp\", \"nmf\", \"knn_basic\", \"knn_baseline\", \"knn_with_means\", \"knn_with_z_score\", \"co_clustering\", \"slope_one\", \"baseline_only\"])</pre>\n<p>The following are the parameters:</p>\n<ul>\n<li>verbose: Will control the verbosity.</li>\n<li>algorithms: Mention the list of algorithms in the form of strings to be optimized. The following choices are available: \u2018svd\u2019, \u2018svdpp\u2019, \u2018nmf\u2019, \u2018knn_basic\u2019, \u2018knn_baseline\u2019, \u2018knn_with_means\u2019, \u2018knn_with_z_score\u2019, \u2018co_clustering\u2019, \u2018slope_one\u2019, \u2018baseline_only\u2019.</li>\n<li>random_state: sets the the seed for the random generator to ensure reproducible results.</li>\n</ul>\n<p><em>Initializing Auto-Surprise Optimization</em></p>\n<p>Using the train method of Engine, we can begin the optimization method. Using the optimization method, we achieve the best algorithm, hyperparameters, best score, and tasks completed.</p>\n<pre># Starting the trainer<br>best_algo, best_params, best_score, tasks = engine.train(<br>    data=data,<br>    target_metric='test_rmse',<br>    cpu_time_limit=60*60,<br>    max_evals=100,<br>    hpo_algo=hyperopt.tpe.suggest<br>)</pre>\n<p>The following are the parameters:</p>\n<ul>\n<li>data: The data for training and testing the\u00a0model</li>\n<li>target_metric: The metric we want to minimize. There are mainly two options available: test_rmse and test_mae.</li>\n<li>cpu_time_limit: The time limit for which we want to train in seconds. The time limit depends on the dataset\u00a0size.</li>\n<li>max_evals: The maximum number of evaluations each algorithm gets for the case of hyper parameter optimization.</li>\n<li>hpo_algo: Hyperopt is used for hyperparameter tuning. By default, it\u2019s set to use TPE, but you can change this to any algorithm supported by hyperopt, such as Adaptive TPE or Random\u00a0search.</li>\n</ul>\n<p><em>Building the Best model with best hyperparameters</em></p>\n<p>After we run the optimization trainer, we can use the best alogithm with the best hypermaters obtained from the train\u00a0method</p>\n<pre># Building the best model with the best hyperparameters<br>best_model = engine.build_model(best_algo, best_params)</pre>\n<p><em>Using the best model for recommending movies to a\u00a0user</em></p>\n<p>We can use the best model built for recommending movies using the following code:</p>\n<pre># Building the full training dataset <br>training_data = data.build_full_trainset()<br>best_model.fit(training_data)<br><br># Predicting movie rating<br>movie_rating = best_model.predict(user, movie)</pre>\n<p>Using the above approach, we can predict the rating for each movie present in our entire dataframe and obtain ten movies that have the highest ratings. These ten movies can be recommended to the\u00a0user.</p>\n<p><em>Model Evaluation Results</em></p>\n<p>For our case, SVD was found to be the best model with the following hyperparamters as mentioned in the table below. We can also see the Loss and the best hyperparameters obtained for other models as well. One advantage of Auto-Surpise is that the model optimization results get automatically printed in a tabular format once the training gets completed.</p>\n<figure><img alt=\"Model Optimization Results\" src=\"https://cdn-images-1.medium.com/max/1024/1*ik6TGxQ1OvmFqj4KzLFICQ.png\"><figcaption>Model Optimization Results</figcaption></figure><h4><strong>Strengths</strong></h4>\n<ul>\n<li>\n<strong>Better Performance:</strong> Auto-Surprise is seen to perform 0.8 to 4% better in terms of RMSE and upto 6.36% better in terms of MAE when compared to the best result from a default algorithm configuration of Auto-Surprise.</li>\n<li>\n<strong>Faster Hyperparameter Optimization:</strong> Auto-Surprise outperforms Gridsearch and Randomsearch in regards to time by a huge margin. In Auto-Surprise takes around 2 hours to obtain best set of hyperparameters. While, Grid Search could take anywhere from 24 to 80 hours\u200a\u2014\u200a12 to 40 times\u00a0longer.</li>\n<li>\n<strong>Considers runtime for algorithms while selecting:</strong> Auto-surprise also considers run-time while choosing the best model. The selected algorithm generally has much lower run- time as compared to the default algorithm of the Surprise\u00a0library.</li>\n<li>\n<strong>Ease of Hyperparameter Optimization:</strong> Auto-Surprise eases the entire process of algorithm selection and hyperparameter optimization to a single line of\u00a0code.</li>\n<li>\n<strong>Ease of Use:</strong> Auto-Surprise is designed to be easy to use for even a novice user who does not know much about machine learning or optimization.</li>\n</ul>\n<h4><strong>Limitations</strong></h4>\n<ul>\n<li>\n<strong>Supports only explicit ratings:</strong> One major downside of Auto-Surprise is that it currently only supports modelling for datasets with explicit ratings. As such, it cannot evaluate models for implicit ratings or content-based filtering. This is mainly because the underlying Surprise library does not support implicit\u00a0ratings.</li>\n<li>\n<strong>Resource Utilization:</strong> As Auto-Surprise runs multiple optimizations in parallel, multiple copies of the original dataset are created. This means that for large datasets, this would require large RAM. This could be solved by offloading some data to persistent storage\u00a0devices.</li>\n<li>\n<strong>Wastage of computation:</strong> Auto-Surprise attempts to optimize multiple algorithms but the output is that of the best model only which can result to wastage of a lot of computation. It would be helpful to make use of those models that performed close to the best performing algorithm.</li>\n<li>\n<strong>Overfitting: </strong>Auto-Surprise can be susceptible to over-fitting in the case of longer evaluations. Like Auto-Sklearn, Auto-Surprise could leverage automated ensemble modeling which can help us solve this\u00a0problem.</li>\n<li>\n<strong>Limits to Surprise Library:</strong> Auto-Surprise can only be applied to the Surprise\u00a0library.</li>\n<li>\n<strong>Limited to Linux systems:</strong> Currently only Linux systems are supported by the Surprise\u00a0library.</li>\n</ul>\n<h4>Conclusion</h4>\n<p>Auto-Surprise allows automation of hyperparameter optimization and model selection for any given set of models and data. By applying this tool to our movie recommendation example, we have shown that it can greatly simplify the process of selecting the best algorithm and tuning hyperparameters, even for those with limited experience in machine learning and hyperparameter tuning. With its ease of use and low code requirements, Auto-Surprise has the potential to revolutionize the field of machine learning and recommender systems by making it more accessible to a wider range of\u00a0users.</p>\n<p>Access to Colab Notebook:</p>\n<p><a href=\"https://colab.research.google.com/drive/1XiqIhExsPZQs3Fd8dIMomSHH971AbUa6?usp=sharing\">https://colab.research.google.com/drive/1XiqIhExsPZQs3Fd8dIMomSHH971AbUa6?usp=sharing</a></p>\n<h4>References</h4>\n<ol>\n<li><a href=\"https://auto-surprise.readthedocs.io/_/downloads/en/stable/pdf/\">https://auto-surprise.readthedocs.io/_/downloads/en/stable/pdf</a></li>\n<li><a href=\"https://surpriselib.com/\">https://surpriselib.com</a></li>\n</ol>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=34b4a6f5b0dd\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<blockquote>Developed using popular libraries like Surprise for recommender algorithms and Hyperopt for hyperparameter tuning, Auto-Surprise streamlines the process of building machine learning models for recommendation systems by allowing automated algorithm selection and hyperparameter optimization.</blockquote>\n<figure><img alt=\"Movies\" src=\"https://cdn-images-1.medium.com/max/1024/1*wjA4BHRf1zyHJn_EVor1Yg.jpeg\"></figure><h4><strong>Motivation and Background</strong></h4>\n<p>In the world of movie recommendations, the importance of data and machine learning has grown exponentially. However, building machine learning recommender models can be complex due to the many variables involved. As a result, several AutoML solutions have emerged, allowing for the automation of tasks like data pre-processing, algorithm selection, hyperparameter tuning, and ensemble modeling.</p>\n<p>One such AutoML tool is Auto-suprise that automates algorithm selection and hyperparameter optimization in a highly parallelized manner, making it a powerful tool for movie recommendation systems. In this blog post, we will explore the features of Auto-suprise and provide an example of how to use it for movie recommendations.</p>\n<h4><strong>Introduction</strong></h4>\n<p>Auto-Surprise is an open source Auto Recommender System library Python library that uses parallel Sequential Model-Based Optimization approach with Tree of Parzens Estimators (TPE) for hyperparameter tuning. Auto- Surprise is built on the Python Surprise library. Surprise is a popular python library which specializes in analyzing and building recommendation models. It provides a variety of algorithms like Normal Predictor (Random), K-Nearest Neighbors (KNN) Basic, KNN with Means, KNN with Z-Score, KNN with Baseline, Singular Value Decomposition (SVD), SVD++, Negative Matrix-Factorization (NMF), Co-Clustering, Slope\u00a0One.</p>\n<p>The Surprise library provides a built-in module that allows Grid Search or Random Search for hyperparamater optimization. However, when it comes to optimizing machine learning models, manually conducting a random search or using GridSearch can be time-consuming and inefficient due to large number of iterations. This can be computationally expensive as well as time consuming. This is where automated methods like Auto-Surprise come in handy. Developed to simplify the algorithm and hyperparameter tuning process, Auto-Surprise is a powerful tool that\u2019s easy to use, even for those who are new to the\u00a0field.</p>\n<h4><strong>Auto-Surprise Optimization Strategy</strong></h4>\n<p>Auto-Surprise leverages a parallel Sequential Model Based Optimization (SMBO) approach to optimize the performance of the recommendation models. SMBO is an iterative optimization method where multiple experiments are conducted sequentially on a surrogate function. The results of each experiment are recorded, and the optimal hyperparameters are determined based on the historical performance of the surrogate function.</p>\n<p>To begin the optimization process, Auto-Surprise sets a minimum loss for the dataset using a random prediction algorithm that each recommendation algorithm must achieve. The algorithms are then optimized in parallel until either a user-defined time limit or a maximum number of evaluations is reached. If any algorithm performs worse than the baseline after a certain number of evaluations, it is excluded from further optimization.</p>\n<p>Auto-Surprise returns the best performing algorithm with the optimized hyperparameters, along with a dictionary containing the performance metrics of all the algorithms. This makes it easy to compare and analyze the performance of different recommendation models. The figure below illustrates the optimization strategy of Auto-Surprise.</p>\n<figure><img alt=\"Optimization strategy for Auto-Surprise\" src=\"https://cdn-images-1.medium.com/max/1024/1*IWYVHrQ3OpBuLwBo3sc2xw.png\"><figcaption>Optimization strategy of Auto-Surprise</figcaption></figure><h4><strong>Movie Recommendation using Auto-Surprise</strong></h4>\n<p>We will now be looking at a scenario where we employ Auto-Surprise for the goal of predicting or recommending movies to users based on the IDs of the user and movies. Using auto-surprise, we can effectively build a movie recommendation model with ease. In my example, I have utilized a dataset that has been gathered using the Kafka streaming platform. However, one can use other readily available datasets like that of <a href=\"https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset\">MovieLens dataset</a> that contains user ratings for various\u00a0movies.</p>\n<p><em>Setting up Auto-Surprise</em></p>\n<p>To begin we first need to install the required dependencies:</p>\n<pre># Installing the required libraries<br>!pip install hyperopt==0.2.5<br>!pip install scikit-surprise<br>!pip install auto-surprise</pre>\n<p>Once we have downloaded the packages and libraries, we can import them using the following python\u00a0code:</p>\n<pre>#Importing the required libraries<br>import hyperopt<br>from surprise import Reader, Dataset<br>from auto_surprise.engine import Engine<br>import pandas as pd<br>import numpy as np</pre>\n<p><em>Reading the data and building the data\u00a0frame</em></p>\n<p>We will be reading the dataset which is stored in a csv format using the read_csv() function of the pandas library. Once we have stored the pandas dataframe we then define the reader using Reader class for parsing the file containing ratings. We then convert the pandas dataframe into a dataset format which can be read for training our\u00a0model.</p>\n<pre># Reading the data from the csv file<br>df = pd.read_csv(&lt;your dataset.csv name in string format&gt;)<br># Building the dataframe for the models using the pandas dataframe<br>reader = Reader(rating_scale=(1,5))<br>data = Dataset.load_from_df(df[['user', 'movie', 'rate']], reader)</pre>\n<p><em>Initializing Auto-Surprise Engine</em></p>\n<p>Once we have read the data and converted it into a suitable form, we then initialize the engine using the Engine class for Auto-Surprise.</p>\n<pre># Intitializing the auto surprise engine with the possible algorithms.<br>engine = Engine(verbose=True, algorithms=[\"svd\", \"svdpp\", \"nmf\", \"knn_basic\", \"knn_baseline\", \"knn_with_means\", \"knn_with_z_score\", \"co_clustering\", \"slope_one\", \"baseline_only\"])</pre>\n<p>The following are the parameters:</p>\n<ul>\n<li>verbose: Will control the verbosity.</li>\n<li>algorithms: Mention the list of algorithms in the form of strings to be optimized. The following choices are available: \u2018svd\u2019, \u2018svdpp\u2019, \u2018nmf\u2019, \u2018knn_basic\u2019, \u2018knn_baseline\u2019, \u2018knn_with_means\u2019, \u2018knn_with_z_score\u2019, \u2018co_clustering\u2019, \u2018slope_one\u2019, \u2018baseline_only\u2019.</li>\n<li>random_state: sets the the seed for the random generator to ensure reproducible results.</li>\n</ul>\n<p><em>Initializing Auto-Surprise Optimization</em></p>\n<p>Using the train method of Engine, we can begin the optimization method. Using the optimization method, we achieve the best algorithm, hyperparameters, best score, and tasks completed.</p>\n<pre># Starting the trainer<br>best_algo, best_params, best_score, tasks = engine.train(<br>    data=data,<br>    target_metric='test_rmse',<br>    cpu_time_limit=60*60,<br>    max_evals=100,<br>    hpo_algo=hyperopt.tpe.suggest<br>)</pre>\n<p>The following are the parameters:</p>\n<ul>\n<li>data: The data for training and testing the\u00a0model</li>\n<li>target_metric: The metric we want to minimize. There are mainly two options available: test_rmse and test_mae.</li>\n<li>cpu_time_limit: The time limit for which we want to train in seconds. The time limit depends on the dataset\u00a0size.</li>\n<li>max_evals: The maximum number of evaluations each algorithm gets for the case of hyper parameter optimization.</li>\n<li>hpo_algo: Hyperopt is used for hyperparameter tuning. By default, it\u2019s set to use TPE, but you can change this to any algorithm supported by hyperopt, such as Adaptive TPE or Random\u00a0search.</li>\n</ul>\n<p><em>Building the Best model with best hyperparameters</em></p>\n<p>After we run the optimization trainer, we can use the best alogithm with the best hypermaters obtained from the train\u00a0method</p>\n<pre># Building the best model with the best hyperparameters<br>best_model = engine.build_model(best_algo, best_params)</pre>\n<p><em>Using the best model for recommending movies to a\u00a0user</em></p>\n<p>We can use the best model built for recommending movies using the following code:</p>\n<pre># Building the full training dataset <br>training_data = data.build_full_trainset()<br>best_model.fit(training_data)<br><br># Predicting movie rating<br>movie_rating = best_model.predict(user, movie)</pre>\n<p>Using the above approach, we can predict the rating for each movie present in our entire dataframe and obtain ten movies that have the highest ratings. These ten movies can be recommended to the\u00a0user.</p>\n<p><em>Model Evaluation Results</em></p>\n<p>For our case, SVD was found to be the best model with the following hyperparamters as mentioned in the table below. We can also see the Loss and the best hyperparameters obtained for other models as well. One advantage of Auto-Surpise is that the model optimization results get automatically printed in a tabular format once the training gets completed.</p>\n<figure><img alt=\"Model Optimization Results\" src=\"https://cdn-images-1.medium.com/max/1024/1*ik6TGxQ1OvmFqj4KzLFICQ.png\"><figcaption>Model Optimization Results</figcaption></figure><h4><strong>Strengths</strong></h4>\n<ul>\n<li>\n<strong>Better Performance:</strong> Auto-Surprise is seen to perform 0.8 to 4% better in terms of RMSE and upto 6.36% better in terms of MAE when compared to the best result from a default algorithm configuration of Auto-Surprise.</li>\n<li>\n<strong>Faster Hyperparameter Optimization:</strong> Auto-Surprise outperforms Gridsearch and Randomsearch in regards to time by a huge margin. In Auto-Surprise takes around 2 hours to obtain best set of hyperparameters. While, Grid Search could take anywhere from 24 to 80 hours\u200a\u2014\u200a12 to 40 times\u00a0longer.</li>\n<li>\n<strong>Considers runtime for algorithms while selecting:</strong> Auto-surprise also considers run-time while choosing the best model. The selected algorithm generally has much lower run- time as compared to the default algorithm of the Surprise\u00a0library.</li>\n<li>\n<strong>Ease of Hyperparameter Optimization:</strong> Auto-Surprise eases the entire process of algorithm selection and hyperparameter optimization to a single line of\u00a0code.</li>\n<li>\n<strong>Ease of Use:</strong> Auto-Surprise is designed to be easy to use for even a novice user who does not know much about machine learning or optimization.</li>\n</ul>\n<h4><strong>Limitations</strong></h4>\n<ul>\n<li>\n<strong>Supports only explicit ratings:</strong> One major downside of Auto-Surprise is that it currently only supports modelling for datasets with explicit ratings. As such, it cannot evaluate models for implicit ratings or content-based filtering. This is mainly because the underlying Surprise library does not support implicit\u00a0ratings.</li>\n<li>\n<strong>Resource Utilization:</strong> As Auto-Surprise runs multiple optimizations in parallel, multiple copies of the original dataset are created. This means that for large datasets, this would require large RAM. This could be solved by offloading some data to persistent storage\u00a0devices.</li>\n<li>\n<strong>Wastage of computation:</strong> Auto-Surprise attempts to optimize multiple algorithms but the output is that of the best model only which can result to wastage of a lot of computation. It would be helpful to make use of those models that performed close to the best performing algorithm.</li>\n<li>\n<strong>Overfitting: </strong>Auto-Surprise can be susceptible to over-fitting in the case of longer evaluations. Like Auto-Sklearn, Auto-Surprise could leverage automated ensemble modeling which can help us solve this\u00a0problem.</li>\n<li>\n<strong>Limits to Surprise Library:</strong> Auto-Surprise can only be applied to the Surprise\u00a0library.</li>\n<li>\n<strong>Limited to Linux systems:</strong> Currently only Linux systems are supported by the Surprise\u00a0library.</li>\n</ul>\n<h4>Conclusion</h4>\n<p>Auto-Surprise allows automation of hyperparameter optimization and model selection for any given set of models and data. By applying this tool to our movie recommendation example, we have shown that it can greatly simplify the process of selecting the best algorithm and tuning hyperparameters, even for those with limited experience in machine learning and hyperparameter tuning. With its ease of use and low code requirements, Auto-Surprise has the potential to revolutionize the field of machine learning and recommender systems by making it more accessible to a wider range of\u00a0users.</p>\n<p>Access to Colab Notebook:</p>\n<p><a href=\"https://colab.research.google.com/drive/1XiqIhExsPZQs3Fd8dIMomSHH971AbUa6?usp=sharing\">https://colab.research.google.com/drive/1XiqIhExsPZQs3Fd8dIMomSHH971AbUa6?usp=sharing</a></p>\n<h4>References</h4>\n<ol>\n<li><a href=\"https://auto-surprise.readthedocs.io/_/downloads/en/stable/pdf/\">https://auto-surprise.readthedocs.io/_/downloads/en/stable/pdf</a></li>\n<li><a href=\"https://surpriselib.com/\">https://surpriselib.com</a></li>\n</ol>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=34b4a6f5b0dd\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":["auto-surprise","machine-learning","hyperparameter-tuning","automl","movie-recommendation"]}]}